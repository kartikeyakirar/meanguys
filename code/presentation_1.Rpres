WhyR Hackaton
========================================================
author: MeanGuys
date: 24.09.2020
autosize: false

Challenge 1 - *Warm up predictions*
========================================================

Based on historical data of stories appearing on Hacker News in 2020 predict

 * The number of new articles to appear between 2020-09-25 00:00 UTC - 2020-09-26 00:00 UTC
 * The total number of new comments under stories published between 2020-09-25 00:00 UTC - 2020-09-26 00:00 UTC
 * The highest number of points obtained by a single article (recorded at 2020-09-26 00:00 UTC) for articles published after 2020-09-25 00:00 UTC

```{r metrics, eval = FALSE}

abs((predicted_n_articles-actual_n_articles)/actual_n_articles) +
abs((predicted_n_comments-actual_n_comments)/actual_n_comments) +
abs((predicted_highest_number_of_points-actual_highest_number_of_points)/actual_highest_number_of_points)

```

Environment
========================================================

```{r setup, message = FALSE, collapse = TRUE, strip.white = TRUE}

knitr::opts_chunk$set(
	message = FALSE,
	warning = FALSE,
	results = "hold",
	strip.white = TRUE
)

load_ibraries <- c("tidyverse", "rvest", "jsonlite", "tidyjson", "lubridate", 
                   "magrittr", "hackeRnews", "R.utils", "tsibble","feasts", "fable")
installed_libraries <- load_ibraries[!load_ibraries %in% installed.packages()]

for(lib in installed_libraries) 
	install.packages(lib, dependences = TRUE)

sapply(load_ibraries, require, character = TRUE)

```

```{r dataImport, include = FALSE, warning = TRUE}

articles <- fromJSON(readLines("../data/articles.json"), flatten = TRUE)
articles_df <- as_tibble(lapply(select(articles, -kids, -title, -id, -type), as.character))

articles_df %<>% rename(comments = descendants)

```

```{r dayOfPrognosis, include = FALSE}

compDay <- ymd_hm("2020-09-25 00:00")
compWeekday <- wday(compDay, 
                    week_start = getOption("lubridate.week.start", 1),
                    locale = "English",
                    label = TRUE)

```


Aggregation
========================================================

```{r colModification}

articles_df$comments %<>% as.integer()
articles_df$score    %<>% as.integer() 
articles_df$time     %<>% ymd_hms()
articles_df$by       %<>% factor()

```

```{r newCols}

articles_df %<>%
    mutate(weekday = wday(time, 
                          week_start = getOption("lubridate.week.start", 1),
                          locale = "English",
                          label = TRUE),
           day = day(time),
           month = month(time, 
                         locale = "English",
                         label = TRUE),
           main_url = str_match(url, "(https?://w{0,3}\\.?)(.*?)(\\.[A-z]*/|$)")[,3]) %>%
  mutate(comp_day = (weekday == compWeekday))

articles_df %>%
  transmute(comments = comments, score = score, day = date(time)) %>%
  group_by(day) %>%
  summarise(max_points = max(score),
            comments = mean(comments),
            score = mean(score)) %>%
  pivot_longer(!day) %>%
  mutate(comp_day = (wday(compDay) == wday(day))) %>%
  as_tsibble(index = day, key = name)-> articles_summarized
  
head(articles_df)

```